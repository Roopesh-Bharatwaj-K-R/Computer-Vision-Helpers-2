{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           File_name Image_Position  Blue  \\\n",
      "0  /home/roopesh/Desktop/New_Corpus/test/front (4...    Upper_Third     0   \n",
      "\n",
      "   Green  Brown  Other  \n",
      "0      0    100      0  \n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv_exp.basic\n",
    "import cv_exp.basic as cv\n",
    "import cv_exp.pupil_detection as pupil_detection\n",
    "import cv_exp.draw as draw\n",
    "import cv_exp.log as log\n",
    "import cv_exp.take as take\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "model_face_detection = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_detection_front.tflite'\n",
    "model_face_landmarks ='/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_landmark.tflite'\n",
    "model_iris_landmarks = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/iris_landmark.tflite'\n",
    "\n",
    "iris_detector = pupil_detection.IrisDetectorMP(model_face_detection_path=model_face_detection,\n",
    "                                                   model_face_landmarks_path=model_face_landmarks,\n",
    "                                                   model_iris_landmarks_path=model_iris_landmarks)\n",
    "\n",
    "# def Mediapipe_Iris_Color(path):\n",
    "#     '''\n",
    "\n",
    "#     This function takes the image in path and Using Mediapipe calculates the Annular Mask of the images,\n",
    "#     then calculates the HSV color of Annular mask.\n",
    "#     and returns the dominant Iris colour percentage in a data frame.\n",
    "#     '''\n",
    "\n",
    "\n",
    "\n",
    "def rgb_to_hsv(r, g, b):\n",
    "    '''\n",
    "    Convert RGB to HSV\n",
    "    returns h,s,v\n",
    "    '''\n",
    "\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    df = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        h = (60 * ((g-b)/df) + 360) % 360\n",
    "    elif mx == g:\n",
    "        h = (60 * ((b-r)/df) + 120) % 360\n",
    "    elif mx == b:\n",
    "        h = (60 * ((r-g)/df) + 240) % 360\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = (df/mx)*100\n",
    "    v = mx*100\n",
    "    return h, s, v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path='/home/roopesh/Desktop/New_Corpus/test/front (4).jpg'\n",
    "\n",
    "image = cv2.imread(path)\n",
    "image_bgr_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # converting from BGR to RGB\n",
    "out_ = image_bgr_rgb.copy()\n",
    "out_pupile_ = image_bgr_rgb.copy()\n",
    "result = iris_detector.detect(image_bgr_rgb)\n",
    "\n",
    "if not result is None:\n",
    "\n",
    "    detected_pupils = result.detected_pupils,\n",
    "    face_rect_detection = result.face_rect_detection_from_landmarks,\n",
    "    face_rect_landmarks = result.face_rect_from_landmarks,\n",
    "    face_landmarks = result.face_landmarks,\n",
    "    face_rect_detection_from = result.face_rect_from_detection,\n",
    "    face_landmarks_from_detection = result.face_landmarks_from_detection,\n",
    "    left_iris_landmarks = result.left_iris_landmarks,\n",
    "    left_eyelid_landmarks = result.left_eyelid_landmarks,\n",
    "    right_iris_landmarks = result.right_iris_landmarks,\n",
    "    right_eyelid_landmarks = result.right_eyelid_landmarks,\n",
    "    left_iris_segmentation = result.left_iris_segmentation,\n",
    "    right_iris_segmentation = result.right_iris_segmentation,\n",
    "    eyes_landmarks = result.eyes_landmarks\n",
    "\n",
    "    # drawing (Optional)\n",
    "\n",
    "    out_pupile = draw.draw_pupils(out_pupile_, result.detected_pupils.left, result.detected_pupils.right, color_center = (255, 255, 255), color_contour = (255, 255, 255))\n",
    "    out_pupile = draw.draw_rect(out_pupile_, result.face_rect_detection_from_landmarks, thickness=6, color=(255, 0, 0))\n",
    "    # out_pupile = draw.draw_list_pointd(out_pupile_, result.left_iris_landmarks,radius=6,color = (255, 255, 255))\n",
    "    # out_pupile= draw.draw_contour(out_pupile_, result.left_iris_segmentation,  thickness=1,color=(0, 0, 255))\n",
    "    # out_pupile = draw.draw_list_pointd(out_pupile_, result.left_eyelid_landmarks,radius=6,color = (255, 0, 0))\n",
    "\n",
    "    # Extraction of specific Points From Left Iris Landmarks (0,1) : Left Iris from Coder's Point of view\n",
    "\n",
    "    left_iris_tuple_of_tuple_Tolist = ([PointD_elements for PointD in left_iris_landmarks for PointD_elements in PointD])\n",
    "    left_iris_points = [(pointD.x, pointD.y) for pointD in left_iris_tuple_of_tuple_Tolist]\n",
    "\n",
    "    center_point_LeftIris=(np.round(left_iris_points[0]))\n",
    "    for left_center_x,left_center_y in [center_point_LeftIris]:\n",
    "         lx, ly = left_center_x,left_center_y\n",
    "\n",
    "    left_point_LeftIris=(np.round(left_iris_points[1]))\n",
    "    for leftIris_left_x,LeftIris_left_y in [left_point_LeftIris]:\n",
    "        LIL_x, LIL_y = leftIris_left_x, LeftIris_left_y\n",
    "\n",
    "    right_point_LeftIris=(np.round(left_iris_points[3]))\n",
    "    for rightIris_x,rightIris_y in [right_point_LeftIris]:\n",
    "        RIL_x, RIL_y = rightIris_x, rightIris_y\n",
    "\n",
    "    Top_point_LeftIris=(np.round(left_iris_points[2]))\n",
    "    for TopIris_x,TopIris_y in [Top_point_LeftIris]:\n",
    "        TI_x, TI_y = TopIris_x, TopIris_y\n",
    "\n",
    "    # Bottom_point_LeftIris=(np.round(left_iris_points[4]))\n",
    "    # for BottomIris_x,BottomIris_y in [Bottom_point_LeftIris]:\n",
    "    #     BI_x, BI_y = BottomIris_x, BottomIris_y\n",
    "\n",
    "\n",
    "    # Distance Formula to calculate the distance between center to left_Iris_ points to get radius of iris\n",
    "    distance_left_iris_center = np.sqrt((lx - LIL_x) ** 2 + (ly - LIL_y) ** 2)\n",
    "\n",
    "    # First Circular mask for entire iris\n",
    "\n",
    "    mask = np.zeros(out_pupile_.shape, dtype=np.uint8)      # Result from Mediapipe added here.\n",
    "    center = (int(lx), int(ly))\n",
    "    radius = (int((distance_left_iris_center) * 0.80))\n",
    "    left_mask = cv2.circle(mask, center, radius,[255,255,255], -1 )\n",
    "    result = cv2.bitwise_and(out_pupile_, left_mask)\n",
    "    result[mask == 0] = 255                                 # adding background Color- white\n",
    "\n",
    "    # cropping iris area from the first circular masked image\n",
    "\n",
    "    x = int((RIL_x)+3)               # x-axis --Landmarks points from top- right point from left iris, +3 for adjusting the size\n",
    "    y = int((TI_y)+3)                # y-axis --Landmarks points from top_ left of left iris, +3 for adjusting the size\n",
    "    h = int(radius*2.35)-3               # height --Radius of iris times 2.35 for adjustment,-3 for adjustment\n",
    "    w = int(radius*2.35)             # width  --Radius of iris times 2.35 for adjustment, -1 for adjustment\n",
    "    crop = result[y:y+h, x:x+w]\n",
    "\n",
    "    # second Circular mask to take inner pupil area alone\n",
    "\n",
    "    mask1 = np.zeros(out_pupile_.shape, dtype=np.uint8)         # Result from Mediapipe added here for second mask.\n",
    "    center1 = (int(lx), int(ly))\n",
    "    radius1 = (int((distance_left_iris_center)* 0.50))          # to scrap pupil area and other reflection area\n",
    "    left_mask1 = cv2.circle(mask1, center1, radius1, (255, 255, 255), -1 )\n",
    "    result1 = cv2.bitwise_and(out_pupile_, left_mask1-255)      # subtracting white region over masked area\n",
    "    result1[mask1 == 0] = 255                                   # adding background Color- white\n",
    "\n",
    "    # Cropping the inner pupil area from the second circular masked image (size should be same as the first masked and cropped result )\n",
    "\n",
    "    x = int(RIL_x)+3         # x-axis --Landmarks points from top- right point from left iris, +3 for adjusting the size\n",
    "    y = int(TI_y)+3          # y-axis --Landmarks points from top_ left of left iris, +3 for adjusting the size\n",
    "    h = int(radius*2.35)-3   # height --Radius of iris times 2.35,-3 for adjustment\n",
    "    w = int(radius*2.35)     # width  --Radius of iris times 2.35, -1 for adjustment\n",
    "    crop1 = result1[y:y+h, x:x+w]\n",
    "\n",
    "    # Bitwise and operation to omit the inner pupil alone and take the rest of the iris area\n",
    "\n",
    "    adding_both_cropped_image = cv2.bitwise_and(crop, crop1)\n",
    "\n",
    "    # Removing NOISE from the Adding_both_cropped_image (<=10,  >=240) in all channel\n",
    "\n",
    "    final_result = np.array(adding_both_cropped_image)\n",
    "    mask = np.all(final_result <= [10, 10, 10], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    mask = np.all(final_result >= [240, 240, 240], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    annular_result = final_result                   # the final result of the iris area from mediapipe\n",
    "\n",
    "    # Additional Cropping the iris masked from the Annular_result to make 3 sub cropped images\n",
    "\n",
    "    x, y = final_result.shape[:2]\n",
    "    half = x//2\n",
    "    top_third_= x//3\n",
    "    Upper_Third = final_result[:top_third_]               # Upper third of the image\n",
    "    top_3 = final_result[top_third_:half]\n",
    "    bottom = final_result[half:]\n",
    "    x1, y1 = bottom.shape[:2]\n",
    "    bottom_third = x1//3\n",
    "    bo_3 = bottom[:bottom_third]\n",
    "    half1 = x1//3\n",
    "    Lower_Third = bottom[half1:]                          # Lower third of the image\n",
    "    Middle_Third = np.vstack((top_3, bo_3))               # middle third of the image\n",
    "\n",
    "    dict01 = dict()\n",
    "    dict01['Upper_Third'] = Upper_Third\n",
    "    dict01['Middle_Third'] = Middle_Third\n",
    "    dict01['Lower_Third'] = Lower_Third\n",
    "\n",
    "    # Printing the cropped iris area from the Annular_result (optional)\n",
    "\n",
    "    annular_result1 = cv2.cvtColor(annular_result, cv2.COLOR_RGB2BGR)\n",
    "    Upper_Third1 = cv2.cvtColor(Upper_Third, cv2.COLOR_RGB2BGR)\n",
    "    Middle_Third1 = cv2.cvtColor(Middle_Third, cv2.COLOR_RGB2BGR)\n",
    "    Lower_Third1 = cv2.cvtColor(Lower_Third, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out_pupile_1 = cv2.cvtColor(out_pupile, cv2.COLOR_RGB2BGR)\n",
    "    out_pupile_1 = cv2.putText(out_pupile_1, \"Left Iris\", (int(TI_x), int(TI_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/annular_Iris_/{file}',annular_result1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Iris_original_/{file}',out_pupile_1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Upper_Third/{file}',Upper_Third1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Middle_Third/{file}',Middle_Third1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Lower_Third/{file}',Lower_Third1)\n",
    "\n",
    "    \n",
    "    #   Reading Image in PIL format for dominant color detection.\n",
    "\n",
    "    dominantColour = []\n",
    "\n",
    "    for keys, values in dict01.items():\n",
    "        pil_image = Image.fromarray(values)\n",
    "        imarray = np.array(pil_image.getdata())\n",
    "        df = pd.DataFrame(imarray, columns=['RED', 'GREEN', 'BLUE'])\n",
    "        (df[(df['RED'] >= 50) | (df['GREEN'] >= 50) | (df['BLUE'] >= 50)])  # For value greater than 50\n",
    "\n",
    "         # K-Means Clustering using Scipy\n",
    "\n",
    "        cluster_size = 3\n",
    "        cluster_centers, _ = kmeans(df.values.astype(float), cluster_size)\n",
    "        index, _ = vq(df.values.astype(float), cluster_centers)\n",
    "        count = np.bincount(index)\n",
    "        sum = np.sum(count)\n",
    "        i, Blue, Green, Brown, Other = 0, 0, 0, 0, 0\n",
    "        for row in cluster_centers:\n",
    "            r = row[0]\n",
    "            g = row[1]\n",
    "            b = row[2]\n",
    "            h, s, v = rgb_to_hsv(r, g, b)   # calling the function to convert RGB to HSV\n",
    "            percent = count[i]*100/sum\n",
    "            if h >= 170 and h < 270:\n",
    "                Blue += percent\n",
    "            elif h >= 60 and h < 170:\n",
    "                Green += percent\n",
    "            elif h >= 300 or h < 40:\n",
    "                Brown += percent\n",
    "            else:\n",
    "                Other += percent\n",
    "            i+=1\n",
    "\n",
    "        # Results of Dominant Color Detection in dataframe\n",
    "\n",
    "        data = [[path, str(keys), int(Blue), int(Green), int(Brown), int(Other) ]]\n",
    "        dominantColour_ = pd.DataFrame(data, columns=['File_name', 'Image_Position', 'Blue', 'Green', 'Brown','Other'])\n",
    "        dominantColour.append(dominantColour_)\n",
    "\n",
    "\n",
    "    print(dominantColour[0])\n",
    "\n",
    "else: print(\"No face detected :\", file)\n",
    "\n",
    " # **************************  END of Dominant Colour Detection **************************\n",
    "\n",
    "\n",
    "def rgb_to_hsv(r, g, b):\n",
    "    '''\n",
    "    Convert RGB to HSV\n",
    "    returns h,s,v\n",
    "    '''\n",
    "\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    df = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        h = (60 * ((g-b)/df) + 360) % 360\n",
    "    elif mx == g:\n",
    "        h = (60 * ((b-r)/df) + 120) % 360\n",
    "    elif mx == b:\n",
    "        h = (60 * ((r-g)/df) + 240) % 360\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = (df/mx)*100\n",
    "    v = mx*100\n",
    "    return h, s, v\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "# # ----------Load Image Directory -------------\n",
    "# # images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Green_Eyes/Green_Iris_Training_Image/' # Directory of the images\n",
    "\n",
    "# # images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Brown_Eyes/Brown_Iris_Training_Image_V4.0/'\n",
    "# # images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Blue_Eyes/Blue_Iris_Training_Image (copy)/'\n",
    "# # images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Green_Eyes/Green_Iris_Training_Image_V4.0/'\n",
    "\n",
    "# # images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Brown_V4.0/'\n",
    "# # images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Blue/'\n",
    "# images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Green/'\n",
    "\n",
    "# files = os.listdir(images_files_dir)\n",
    "# # sorted_file=sorted(files, key=lambda x : int(x[5:-4]))\n",
    "# for idx, file in enumerate(files):\n",
    "#     image_path = images_files_dir + file\n",
    "#     # print('debug', file)\n",
    "#     mediapipe_iris_color_chart = Mediapipe_Iris_Color(image_path)           # Calling the Mediapipe_Iris_Color(image_path)\n",
    "#     print(mediapipe_iris_color_chart)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df[(df['RED'] >= 20) & (df['GREEN'] >= 20) & (df['BLUE'] >= 20)])is True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(dominantColour))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Image_Position</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Brown</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>Upper_Third</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>Middle_Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>Lower_Third</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           File_name Image_Position  Blue  \\\n",
       "0  /home/roopesh/Desktop/New_Corpus/Brown/front (...    Upper_Third   100   \n",
       "0  /home/roopesh/Desktop/New_Corpus/Brown/front (...   Middle_Third     0   \n",
       "0  /home/roopesh/Desktop/New_Corpus/Brown/front (...    Lower_Third     0   \n",
       "\n",
       "   Green  Brown  Other  \n",
       "0      0      0      0  \n",
       "0      0     70     29  \n",
       "0      0     42     57  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat= pd.concat(dominantColour)\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat=cat.reset_index(drop=True)\n",
    "cat=cat.set_index('Image_Position')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Blue</th>\n",
       "      <th>Green</th>\n",
       "      <th>Brown</th>\n",
       "      <th>Other</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Image_Position</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Upper_Third</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Middle_Third</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lower_Third</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        File_name  Blue  \\\n",
       "Image_Position                                                            \n",
       "Upper_Third     /home/roopesh/Desktop/New_Corpus/Brown/front (...   100   \n",
       "Middle_Third    /home/roopesh/Desktop/New_Corpus/Brown/front (...     0   \n",
       "Lower_Third     /home/roopesh/Desktop/New_Corpus/Brown/front (...     0   \n",
       "\n",
       "                Green  Brown  Other  \n",
       "Image_Position                       \n",
       "Upper_Third         0      0      0  \n",
       "Middle_Third        0     70     29  \n",
       "Lower_Third         0     42     57  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1=cat.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1={'File_name': {'Upper_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg',\n",
    "  'Middle_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg',\n",
    "  'Lower_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg'},\n",
    " 'Blue': {'Upper_Third': 0, 'Middle_Third': 0, 'Lower_Third': 0},\n",
    " 'Green': {'Upper_Third': 0, 'Middle_Third': 0, 'Lower_Third': 0},\n",
    " 'Brown': {'Upper_Third': 100, 'Middle_Third': 24, 'Lower_Third': 100},\n",
    " 'Other': {'Upper_Third': 0, 'Middle_Third': 75, 'Lower_Third': 0}} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                               0\n",
      "File_name      /home/roopesh/Desktop/New_Corpus/Brown/front (...\n",
      "Conflict_Type                                       All_conflict\n",
      "Blue                                                         0.0\n",
      "Green                                                        0.0\n",
      "Brown                                                       62.0\n",
      "Other                                                       37.5\n"
     ]
    }
   ],
   "source": [
    "def check_5Percent_range(x,y):\n",
    "    flg=False\n",
    "    if x < y:\n",
    "        if x+(x*0.05) >= y:\n",
    "            flg=True\n",
    "    elif x > y:\n",
    "        if x - (x*0.05) <= y:\n",
    "            flg=True\n",
    "    elif x==y:\n",
    "        flg=True\n",
    "    return flg\n",
    "\n",
    "# Upper Lower Middle Third  \n",
    "\n",
    "Blue_All_Equal=check_5Percent_range(dict1['Blue']['Upper_Third'],dict1['Blue']['Middle_Third']) and check_5Percent_range(dict1['Blue']['Upper_Third'],dict1['Blue']['Lower_Third'])and check_5Percent_range(dict1['Blue']['Lower_Third'],dict1['Blue']['Middle_Third'])\n",
    "Brown_All_Equal=check_5Percent_range(dict1['Brown']['Upper_Third'],dict1['Brown']['Middle_Third']) and check_5Percent_range(dict1['Brown']['Upper_Third'],dict1['Brown']['Lower_Third'])and check_5Percent_range(dict1['Brown']['Lower_Third'],dict1['Brown']['Middle_Third'])\n",
    "Green_All_Equal=check_5Percent_range(dict1['Green']['Upper_Third'],dict1['Green']['Middle_Third']) and check_5Percent_range(dict1['Green']['Upper_Third'],dict1['Green']['Lower_Third'])and check_5Percent_range(dict1['Green']['Lower_Third'],dict1['Green']['Middle_Third'])\n",
    "Other_All_Equal = check_5Percent_range(dict1['Other']['Upper_Third'],dict1['Other']['Middle_Third']) and check_5Percent_range(dict1['Other']['Upper_Third'],dict1['Other']['Lower_Third'])and check_5Percent_range(dict1['Other']['Lower_Third'],dict1['Other']['Middle_Third'])\n",
    "\n",
    "# Upper and Middle Third\n",
    "\n",
    "Blue_Upper_Middle_Equal = check_5Percent_range(dict1['Blue']['Upper_Third'],dict1['Blue']['Middle_Third'])\n",
    "Green_Upper_Middle_Equal = check_5Percent_range(dict1['Green']['Upper_Third'],dict1['Green']['Middle_Third'])\n",
    "Brown_Upper_Middle_Equal = check_5Percent_range(dict1['Brown']['Upper_Third'],dict1['Brown']['Middle_Third'])\n",
    "Other_Upper_Middle_Equal = check_5Percent_range(dict1['Other']['Upper_Third'],dict1['Other']['Middle_Third'])\n",
    "\n",
    "Upper_Middle = Blue_Upper_Middle_Equal is False or True and Green_Upper_Middle_Equal is False or True and Brown_Upper_Middle_Equal is False or True and Other_Upper_Middle_Equal is False or True\n",
    "\n",
    "\n",
    "# Middle and Lower Third\n",
    "\n",
    "Blue_Middle_Lower_Equal = check_5Percent_range(dict1['Blue']['Lower_Third'],dict1['Blue']['Middle_Third'])\n",
    "Green_Middle_Lower_Equal =check_5Percent_range(dict1['Green']['Lower_Third'],dict1['Green']['Middle_Third'])\n",
    "Brown_Middle_Lower_Equal = check_5Percent_range(dict1['Brown']['Lower_Third'],dict1['Brown']['Middle_Third'])\n",
    "Other_Middle_Lower_Equal =check_5Percent_range(dict1['Other']['Lower_Third'],dict1['Other']['Middle_Third'])\n",
    "\n",
    "Middle_Lower = (Blue_Middle_Lower_Equal and Green_Middle_Lower_Equal and Brown_Middle_Lower_Equal and\n",
    "                Other_Middle_Lower_Equal)\n",
    "\n",
    "#  Upper and Lower Third\n",
    "\n",
    "Blue_Upper_Lower_Equal = check_5Percent_range(dict1['Blue']['Upper_Third'],dict1['Blue']['Lower_Third'])\n",
    "Green_Upper_Lower_Equal = check_5Percent_range(dict1['Green']['Upper_Third'],dict1['Green']['Lower_Third'])\n",
    "Brown_Upper_Lower_Equal = check_5Percent_range(dict1['Brown']['Upper_Third'],dict1['Brown']['Lower_Third'])\n",
    "Other_Upper_Lower_Equal = check_5Percent_range(dict1['Other']['Upper_Third'],dict1['Other']['Lower_Third'])\n",
    "\n",
    "Upper_Lower = Blue_Upper_Lower_Equal is False and Green_Upper_Lower_Equal is False and Brown_Upper_Lower_Equal is False and Other_Upper_Lower_Equal is False\n",
    "\n",
    "# Upper Middle Lower Not Equal  \n",
    "\n",
    "all_conflict = Blue_All_Equal is False and Green_All_Equal is False and Brown_All_Equal is False and  Other_All_Equal is False\n",
    "\n",
    "# 2.  Upper Middle Lower Agree\n",
    "\n",
    "if Blue_All_Equal and Green_All_Equal and  Green_All_Equal and Other_All_Equal is True:    \n",
    "\n",
    "    All_Equal_Blue=  (dict1['Blue']['Middle_Third'])\n",
    "    All_Equal_green= (dict1['Green']['Middle_Third'])\n",
    "    All_Equal_brown= (dict1['Brown']['Middle_Third'])\n",
    "    All_Equal_other= (dict1['Other']['Middle_Third'])\n",
    "   \n",
    "    conflict_result= {'File_name': 'path','Blue': All_Equal_Blue,\n",
    "                      'Green': All_Equal_green,'Brown': All_Equal_brown,'Other': All_Equal_other}\n",
    "   \n",
    "    print(conflict_result, 'No Conflicts')\n",
    "    \n",
    "    data1 = [[path, str('No Conflicts'), float(All_Equal_Blue), float(All_Equal_green), float(All_Equal_brown), float(All_Equal_Other) ]]\n",
    "    conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n",
    "    print (conflict_result)\n",
    "    \n",
    "   \n",
    "#  3. Upper/ Middle or Middle/Lower Agree\n",
    "\n",
    "elif  Upper_Middle is False and Middle_Lower is True:\n",
    "   \n",
    "    upper_middle_blue =  (dict1['Blue']['Upper_Third']/2 + dict1['Blue']['Middle_Third']/2)\n",
    "    upper_middle_green = (dict1['Green']['Upper_Third']/2 + dict1['Green']['Middle_Third']/2)\n",
    "    upper_middle_brown = (dict1['Brown']['Upper_Third']/2 + dict1['Brown']['Middle_Third']/2)\n",
    "    upper_middle_other = (dict1['Other']['Upper_Third']/2 + dict1['Other']['Middle_Third']/2)\n",
    "   \n",
    "    data1 = [[path, str('Conflict with Upper and Lower'), float(upper_middle_blue), float(upper_middle_green), float(upper_middle_brown), float(upper_middle_other) ]]\n",
    "    conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n",
    "    print (conflict_result)\n",
    "   \n",
    "elif  Middle_Lower is False and Upper_Lower is True:\n",
    "   \n",
    "    Middle_Lower_blue = (dict1['Blue']['Middle_Third']/2 + dict1['Blue']['Lower_Third']/2)\n",
    "    Middle_Lower_green = (dict1['Green']['Middle_Third']/2 + dict1['Green']['Lower_Third']/2)\n",
    "    Middle_Lower_brown = (dict1['Brown']['Middle_Third']/2 + dict1['Brown']['Lower_Third']/2)\n",
    "    Middle_Lower_other = (dict1['Other']['Middle_Third']/2 + dict1['Other']['Lower_Third']/2)\n",
    "   \n",
    "    data1 = [[path, str('Conflict with Upper and Middle'), float(Middle_Lower_blue), float(Middle_Lower_green), float(Middle_Lower_Brown), float(Middle_Lower_other) ]]\n",
    "    conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n",
    "    print (conflict_result)\n",
    "   \n",
    "# 5 Upper Middle Bottom -Conflict\n",
    "\n",
    "elif all_conflict is False:\n",
    "   \n",
    "    conflict_Blue  = (1*(dict1['Blue']['Upper_Third'] + dict1['Blue']['Lower_Third'])+ 2*(dict1['Blue']['Middle_Third']))/4\n",
    "    conflict_Green = (1*(dict1['Green']['Upper_Third'] + dict1['Green']['Lower_Third'])+ 2*(dict1['Green']['Middle_Third']))/4\n",
    "    conflict_Brown = (1*(dict1['Brown']['Upper_Third'] + dict1['Brown']['Lower_Third'])+ 2*(dict1['Brown']['Middle_Third']))/4\n",
    "    conflict_other = (1*(dict1['Other']['Upper_Third'] + dict1['Other']['Lower_Third'])+ 2*(dict1['Other']['Middle_Third']) )/4\n",
    "\n",
    "    data1 = [[path, str('All_conflict'), float(conflict_Blue), float(conflict_Green), float(conflict_Brown), float(conflict_other) ]]\n",
    "    conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n",
    "\n",
    "    print (conflict_result)\n",
    "\n",
    "# 4 Top and Bottom Agree but conflict in middle\n",
    "\n",
    "elif Upper_Lower is False and Upper_Lower or Upper_Middle is True:\n",
    "    \n",
    "    conflict_Blue  = (1*(dict1['Blue']['Upper_Third'] + dict1['Blue']['Lower_Third'])+ 2*(dict1['Blue']['Middle_Third']))/4\n",
    "    conflict_Green = (1*(dict1['Green']['Upper_Third'] + dict1['Green']['Lower_Third'])+ 2*(dict1['Green']['Middle_Third']))/4\n",
    "    conflict_Brown = (1*(dict1['Brown']['Upper_Third'] + dict1['Brown']['Lower_Third'])+ 2*(dict1['Brown']['Middle_Third']))/4\n",
    "    conflict_other = (1*(dict1['Other']['Upper_Third'] + dict1['Other']['Lower_Third'])+ 2*(dict1['Other']['Middle_Third']) )/4\n",
    "\n",
    "   \n",
    "    data1 = [[path, str('Conflict in Middle'), float(conflict_Blue), float(conflict_Green), float(conflict_Brown), float(conflict_other) ]]\n",
    "    conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n",
    "\n",
    "    print (conflict_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Upper_Lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [[path, str('Conflict with Upper and Middle'), float(conflict_Blue), float(conflict_Green), float(conflict_Brown), float(conflict_Other) ]]\n",
    "conflict_result = pd.DataFrame(data1, columns=['File_name', 'Conflict_Type', 'Blue', 'Green', 'Brown','Other']).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>File_name</th>\n",
       "      <td>/home/roopesh/Desktop/New_Corpus/Brown/front (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conflict_Type</th>\n",
       "      <td>All_conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue</th>\n",
       "      <td>24.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Green</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown</th>\n",
       "      <td>45.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>28.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               0\n",
       "File_name      /home/roopesh/Desktop/New_Corpus/Brown/front (...\n",
       "Conflict_Type                                       All_conflict\n",
       "Blue                                                       24.75\n",
       "Green                                                        0.0\n",
       "Brown                                                       45.5\n",
       "Other                                                      28.75"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflict_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'File_name': {0: '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg'}, 'Image_Position': {0: 'Upper_Third'}, 'Blue': {0: 100}, 'Green': {0: 0}, 'Brown': {0: 0}, 'Other': {0: 0}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Upper_Third'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [133]\u001b[0m, in \u001b[0;36m<cell line: 80>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mprint\u001b[39m(dict1)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Upper Lower Middle Third  \u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m Blue_All_Equal\u001b[38;5;241m=\u001b[39mcheck_5Percent_range(\u001b[43mdict1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBlue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mUpper_Third\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m,dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlue\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    273\u001b[0m Brown_All_Equal\u001b[38;5;241m=\u001b[39mcheck_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBrown\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    274\u001b[0m Green_All_Equal\u001b[38;5;241m=\u001b[39mcheck_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUpper_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;129;01mand\u001b[39;00m check_5Percent_range(dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower_Third\u001b[39m\u001b[38;5;124m'\u001b[39m],dict1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGreen\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiddle_Third\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Upper_Third'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import cv_exp.basic\n",
    "import cv_exp.basic as cv\n",
    "import cv_exp.pupil_detection as pupil_detection\n",
    "import cv_exp.draw as draw\n",
    "import cv_exp.log as log\n",
    "import cv_exp.take as take\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "model_face_detection = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_detection_front.tflite'\n",
    "model_face_landmarks ='/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_landmark.tflite'\n",
    "model_iris_landmarks = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/iris_landmark.tflite'\n",
    "\n",
    "iris_detector = pupil_detection.IrisDetectorMP(model_face_detection_path=model_face_detection,\n",
    "                                                   model_face_landmarks_path=model_face_landmarks,\n",
    "                                                   model_iris_landmarks_path=model_iris_landmarks)\n",
    "\n",
    "# def Mediapipe_Iris_Color(path):\n",
    "#     '''\n",
    "\n",
    "#     This function takes the image in path and Using Mediapipe calculates the Annular Mask of the images,\n",
    "#     then calculates the HSV color of Annular mask.\n",
    "#     and returns the dominant Iris colour percentage in a data frame.\n",
    "#     '''\n",
    "\n",
    "\n",
    "\n",
    "def rgb_to_hsv(r, g, b):\n",
    "    '''\n",
    "    Convert RGB to HSV\n",
    "    returns h,s,v\n",
    "    '''\n",
    "\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    df = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        h = (60 * ((g-b)/df) + 360) % 360\n",
    "    elif mx == g:\n",
    "        h = (60 * ((b-r)/df) + 120) % 360\n",
    "    elif mx == b:\n",
    "        h = (60 * ((r-g)/df) + 240) % 360\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = (df/mx)*100\n",
    "    v = mx*100\n",
    "    return h, s, v\n",
    "\n",
    "# def Mediapipe_Iris_Color(path):\n",
    "#     '''\n",
    "\n",
    "#     This function takes the image in path and Using Mediapipe calculates the Annular Mask of the images,\n",
    "#     then calculates the HSV color of Annular mask.\n",
    "#     and returns the dominant Iris colour percentage in a data frame.\n",
    "#     '''\n",
    "\n",
    "\n",
    "\n",
    "path='/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg'\n",
    "\n",
    "image = cv2.imread(path)\n",
    "image_bgr_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # converting from BGR to RGB\n",
    "out_ = image_bgr_rgb.copy()\n",
    "out_pupile_ = image_bgr_rgb.copy()\n",
    "result = iris_detector.detect(image_bgr_rgb)\n",
    "\n",
    "if not result is None:\n",
    "\n",
    "    detected_pupils = result.detected_pupils,\n",
    "    face_rect_detection = result.face_rect_detection_from_landmarks,\n",
    "    face_rect_landmarks = result.face_rect_from_landmarks,\n",
    "    face_landmarks = result.face_landmarks,\n",
    "    face_rect_detection_from = result.face_rect_from_detection,\n",
    "    face_landmarks_from_detection = result.face_landmarks_from_detection,\n",
    "    left_iris_landmarks = result.left_iris_landmarks,\n",
    "    left_eyelid_landmarks = result.left_eyelid_landmarks,\n",
    "    right_iris_landmarks = result.right_iris_landmarks,\n",
    "    right_eyelid_landmarks = result.right_eyelid_landmarks,\n",
    "    left_iris_segmentation = result.left_iris_segmentation,\n",
    "    right_iris_segmentation = result.right_iris_segmentation,\n",
    "    eyes_landmarks = result.eyes_landmarks\n",
    "\n",
    "    # drawing (Optional)\n",
    "\n",
    "    out_pupile = draw.draw_pupils(out_pupile_, result.detected_pupils.left, result.detected_pupils.right, color_center = (255, 255, 255), color_contour = (255, 255, 255))\n",
    "    out_pupile = draw.draw_rect(out_pupile_, result.face_rect_detection_from_landmarks, thickness=6, color=(255, 0, 0))\n",
    "    # out_pupile = draw.draw_list_pointd(out_pupile_, result.left_iris_landmarks,radius=6,color = (255, 255, 255))\n",
    "    # out_pupile= draw.draw_contour(out_pupile_, result.left_iris_segmentation,  thickness=1,color=(0, 0, 255))\n",
    "    # out_pupile = draw.draw_list_pointd(out_pupile_, result.left_eyelid_landmarks,radius=6,color = (255, 0, 0))\n",
    "\n",
    "    # Extraction of specific Points From Left Iris Landmarks (0,1) : Left Iris from Coder's Point of view\n",
    "\n",
    "    left_iris_tuple_of_tuple_Tolist = ([PointD_elements for PointD in left_iris_landmarks for PointD_elements in PointD])\n",
    "    left_iris_points = [(pointD.x, pointD.y) for pointD in left_iris_tuple_of_tuple_Tolist]\n",
    "\n",
    "    center_point_LeftIris=(np.round(left_iris_points[0]))\n",
    "    for left_center_x,left_center_y in [center_point_LeftIris]:\n",
    "         lx, ly = left_center_x,left_center_y\n",
    "\n",
    "    left_point_LeftIris=(np.round(left_iris_points[1]))\n",
    "    for leftIris_left_x,LeftIris_left_y in [left_point_LeftIris]:\n",
    "        LIL_x, LIL_y = leftIris_left_x, LeftIris_left_y\n",
    "\n",
    "    right_point_LeftIris=(np.round(left_iris_points[3]))\n",
    "    for rightIris_x,rightIris_y in [right_point_LeftIris]:\n",
    "        RIL_x, RIL_y = rightIris_x, rightIris_y\n",
    "\n",
    "    Top_point_LeftIris=(np.round(left_iris_points[2]))\n",
    "    for TopIris_x,TopIris_y in [Top_point_LeftIris]:\n",
    "        TI_x, TI_y = TopIris_x, TopIris_y\n",
    "\n",
    "    # Bottom_point_LeftIris=(np.round(left_iris_points[4]))\n",
    "    # for BottomIris_x,BottomIris_y in [Bottom_point_LeftIris]:\n",
    "    #     BI_x, BI_y = BottomIris_x, BottomIris_y\n",
    "\n",
    "\n",
    "    # Distance Formula to calculate the distance between center to left_Iris_ points to get radius of iris\n",
    "    distance_left_iris_center = np.sqrt((lx - LIL_x) ** 2 + (ly - LIL_y) ** 2)\n",
    "\n",
    "    # First Circular mask for entire iris\n",
    "\n",
    "    mask = np.zeros(out_pupile_.shape, dtype=np.uint8)      # Result from Mediapipe added here.\n",
    "    center = (int(lx), int(ly))\n",
    "    radius = (int((distance_left_iris_center) * 0.80))\n",
    "    left_mask = cv2.circle(mask, center, radius,[255,255,255], -1 )\n",
    "    result = cv2.bitwise_and(out_pupile_, left_mask)\n",
    "    result[mask == 0] = 255                                 # adding background Color- white\n",
    "\n",
    "    # cropping iris area from the first circular masked image\n",
    "\n",
    "    x = int((RIL_x)+3)               # x-axis --Landmarks points from top- right point from left iris, +3 for adjusting the size\n",
    "    y = int((TI_y)+3)                # y-axis --Landmarks points from top_ left of left iris, +3 for adjusting the size\n",
    "    h = int(radius*2.35)-3               # height --Radius of iris times 2.35 for adjustment,-3 for adjustment\n",
    "    w = int(radius*2.35)             # width  --Radius of iris times 2.35 for adjustment, -1 for adjustment\n",
    "    crop = result[y:y+h, x:x+w]\n",
    "\n",
    "    # second Circular mask to take inner pupil area alone\n",
    "\n",
    "    mask1 = np.zeros(out_pupile_.shape, dtype=np.uint8)         # Result from Mediapipe added here for second mask.\n",
    "    center1 = (int(lx), int(ly))\n",
    "    radius1 = (int((distance_left_iris_center)* 0.50))          # to scrap pupil area and other reflection area\n",
    "    left_mask1 = cv2.circle(mask1, center1, radius1, (255, 255, 255), -1 )\n",
    "    result1 = cv2.bitwise_and(out_pupile_, left_mask1-255)      # subtracting white region over masked area\n",
    "    result1[mask1 == 0] = 255                                   # adding background Color- white\n",
    "\n",
    "    # Cropping the inner pupil area from the second circular masked image (size should be same as the first masked and cropped result )\n",
    "\n",
    "    x = int(RIL_x)+3         # x-axis --Landmarks points from top- right point from left iris, +3 for adjusting the size\n",
    "    y = int(TI_y)+3          # y-axis --Landmarks points from top_ left of left iris, +3 for adjusting the size\n",
    "    h = int(radius*2.35)-3   # height --Radius of iris times 2.35,-3 for adjustment\n",
    "    w = int(radius*2.35)     # width  --Radius of iris times 2.35, -1 for adjustment\n",
    "    crop1 = result1[y:y+h, x:x+w]\n",
    "\n",
    "    # Bitwise and operation to omit the inner pupil alone and take the rest of the iris area\n",
    "\n",
    "    adding_both_cropped_image = cv2.bitwise_and(crop, crop1)\n",
    "\n",
    "    # Removing NOISE from the Adding_both_cropped_image (<=10,  >=240) in all channel\n",
    "\n",
    "    final_result = np.array(adding_both_cropped_image)\n",
    "    mask = np.all(final_result <= [10, 10, 10], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    mask = np.all(final_result >= [240, 240, 240], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    annular_result = final_result                   # the final result of the iris area from mediapipe\n",
    "\n",
    "    # Additional Cropping the iris masked from the Annular_result to make 3 sub cropped images\n",
    "\n",
    "    x, y = final_result.shape[:2]\n",
    "    half = x//2\n",
    "    top_third_= x//3\n",
    "    Upper_Third = final_result[:top_third_]               # Upper third of the image\n",
    "    top_3 = final_result[top_third_:half]\n",
    "    bottom = final_result[half:]\n",
    "    x1, y1 = bottom.shape[:2]\n",
    "    bottom_third = x1//3\n",
    "    bo_3 = bottom[:bottom_third]\n",
    "    half1 = x1//3\n",
    "    Lower_Third = bottom[half1:]                          # Lower third of the image\n",
    "    Middle_Third = np.vstack((top_3, bo_3))               # middle third of the image\n",
    "\n",
    "    dict01 = dict()\n",
    "    dict01['Upper_Third'] = Upper_Third\n",
    "    dict01['Middle_Third'] = Middle_Third\n",
    "    dict01['Lower_Third'] = Lower_Third\n",
    "\n",
    "    # Printing the cropped iris area from the Annular_result (optional)\n",
    "\n",
    "    annular_result1 = cv2.cvtColor(annular_result, cv2.COLOR_RGB2BGR)\n",
    "    Upper_Third1 = cv2.cvtColor(Upper_Third, cv2.COLOR_RGB2BGR)\n",
    "    Middle_Third1 = cv2.cvtColor(Middle_Third, cv2.COLOR_RGB2BGR)\n",
    "    Lower_Third1 = cv2.cvtColor(Lower_Third, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out_pupile_1 = cv2.cvtColor(out_pupile, cv2.COLOR_RGB2BGR)\n",
    "    out_pupile_1 = cv2.putText(out_pupile_1, \"Left Iris\", (int(TI_x), int(TI_y)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/annular_Iris_/{file}',annular_result1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Iris_original_/{file}',out_pupile_1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Upper_Third/{file}',Upper_Third1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Middle_Third/{file}',Middle_Third1)\n",
    "#     cv2.imwrite(f'/home/roopesh/Desktop/new_cvexp_results/V2.0/folder/Lower_Third/{file}',Lower_Third1)\n",
    "\n",
    "\n",
    "    #   Reading Image in PIL format for dominant color detection.\n",
    "\n",
    "    dominantColour = []\n",
    "\n",
    "    for keys, values in dict01.items():\n",
    "        pil_image = Image.fromarray(values)\n",
    "        imarray = np.array(pil_image.getdata())\n",
    "        df = pd.DataFrame(imarray, columns=['RED', 'GREEN', 'BLUE'])\n",
    "        df = pd.DataFrame(df[(df['RED'] >= 50) | (df['GREEN'] >= 50) | (df['BLUE'] >= 50)])  # For value greater than 50\n",
    "\n",
    "         # K-Means Clustering using Scipy\n",
    "\n",
    "        cluster_size = 3\n",
    "        cluster_centers, _ = kmeans(df.values.astype(float), cluster_size)\n",
    "        index, _ = vq(df.values.astype(float), cluster_centers)\n",
    "        count = np.bincount(index)\n",
    "        sum = np.sum(count)\n",
    "        i, Blue, Green, Brown, Other = 0, 0, 0, 0, 0\n",
    "        for row in cluster_centers:\n",
    "            r = row[0]\n",
    "            g = row[1]\n",
    "            b = row[2]\n",
    "            h, s, v = rgb_to_hsv(r, g, b)   # calling the function to convert RGB to HSV\n",
    "            percent = count[i]*100/sum\n",
    "            if h >= 170 and h < 270:\n",
    "                Blue += percent\n",
    "            elif h >= 60 and h < 170:\n",
    "                Green += percent\n",
    "            elif h >= 300 or h < 40:\n",
    "                Brown += percent\n",
    "            else:\n",
    "                Other += percent\n",
    "            i+=1\n",
    "\n",
    "        # Results of Dominant Color Detection in dataframe\n",
    "\n",
    "        data = [[path, str(keys), int(Blue), int(Green), int(Brown), int(Other) ]]\n",
    "        dominantColour_ = pd.DataFrame(data, columns=['File_name', 'Image_Position', 'Blue', 'Green', 'Brown','Other']) \n",
    "        dominantColour.append(dominantColour_)\n",
    "        \n",
    "     \n",
    "   return conflict_result\n",
    "\n",
    "#         print(dominantColour[0])\n",
    "\n",
    "    else: print(\"No face detected :\", file)\n",
    "\n",
    "     # **************************  END of Dominant Colour Detection **************************\n",
    "\n",
    "\n",
    "    \n",
    "def check_5Percent_range(x,y):\n",
    "    flg=False\n",
    "    if x < y:\n",
    "        if x+(x*0.05) >= y:\n",
    "            flg=True\n",
    "    elif x > y:\n",
    "        if x - (x*0.05) <= y:\n",
    "            flg=True\n",
    "    elif x==y:\n",
    "        flg=True\n",
    "    return flg\n",
    "    \n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "# ----------Load Image Directory -------------\n",
    "# images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Green_Eyes/Green_Iris_Training_Image/' # Directory of the images\n",
    "\n",
    "# images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Brown_Eyes/Brown_Iris_Training_Image_V4.0/'\n",
    "# images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Blue_Eyes/Blue_Iris_Training_Image (copy)/'\n",
    "# images_files_dir= '/home/roopesh/Desktop/new_cvexp_results/V2.0/New_Green_Eyes/Green_Iris_Training_Image_V4.0/'\n",
    "\n",
    "# images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Brown_V4.0/'\n",
    "# images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Blue/'\n",
    "    images_files_dir= '/home/roopesh/Desktop/New_Corpus_v3/Green/'\n",
    "\n",
    "    files = os.listdir(images_files_dir)\n",
    "    # sorted_file=sorted(files, key=lambda x : int(x[5:-4]))\n",
    "    for idx, file in enumerate(files):\n",
    "        image_path = images_files_dir + file\n",
    "        # print('debug', file)\n",
    "        mediapipe_iris_color_chart = Mediapipe_Iris_Color(image_path)           # Calling the Mediapipe_Iris_Color(image_path)\n",
    "        print(mediapipe_iris_color_chart)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'File_name': {'Upper_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg',\n",
       "  'Middle_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg',\n",
       "  'Lower_Third': '/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg'},\n",
       " 'Blue': {'Upper_Third': 99, 'Middle_Third': 0, 'Lower_Third': 0},\n",
       " 'Green': {'Upper_Third': 0, 'Middle_Third': 0, 'Lower_Third': 0},\n",
       " 'Brown': {'Upper_Third': 0, 'Middle_Third': 70, 'Lower_Third': 42},\n",
       " 'Other': {'Upper_Third': 0, 'Middle_Third': 29, 'Lower_Third': 57}}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newPython3.8",
   "language": "python",
   "name": "newpython3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
