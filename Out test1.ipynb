{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rgb_to_hsv(r, g, b):\n",
    "    '''\n",
    "    Convert RGB to HSV\n",
    "    returns h,s,v\n",
    "    '''\n",
    "\n",
    "    r, g, b = r/255.0, g/255.0, b/255.0\n",
    "    mx = max(r, g, b)\n",
    "    mn = min(r, g, b)\n",
    "    df = mx-mn\n",
    "    if mx == mn:\n",
    "        h = 0\n",
    "    elif mx == r:\n",
    "        h = (60 * ((g-b)/df) + 360) % 360\n",
    "    elif mx == g:\n",
    "        h = (60 * ((b-r)/df) + 120) % 360\n",
    "    elif mx == b:\n",
    "        h = (60 * ((r-g)/df) + 240) % 360\n",
    "    if mx == 0:\n",
    "        s = 0\n",
    "    else:\n",
    "        s = (df/mx)*100\n",
    "    v = mx*100\n",
    "    return h, s, v\n",
    "\n",
    "\n",
    "    plt.imshow(final_result)\n",
    "    plt.show\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import cv_exp.basic\n",
    "import cv_exp.basic as cv\n",
    "import cv_exp.pupil_detection as pupil_detection\n",
    "import cv_exp.draw as draw\n",
    "import cv_exp.log as log\n",
    "import cv_exp.take as take\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import kmeans, vq\n",
    "\n",
    "\n",
    "\n",
    "model_face_detection = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_detection_front.tflite'\n",
    "model_face_landmarks ='/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/face_landmark.tflite'\n",
    "model_iris_landmarks = '/home/roopesh/Desktop/MediaPipe_new_cv_exp/cv-exp-framework-master/data/models/iris_landmark.tflite'\n",
    "\n",
    "iris_detector = pupil_detection.IrisDetectorMP(model_face_detection_path=model_face_detection,\n",
    "                                                   model_face_landmarks_path=model_face_landmarks,\n",
    "                                                   model_iris_landmarks_path=model_iris_landmarks)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "# def Mediapipe_Iris_Color(path):\n",
    "#     '''\n",
    "#     This function takes the image in path and Using Mediapipe calculates the Annular Mask of the images,\n",
    "#     then calculates the HSV color of Annular mask.\n",
    "#     and returns the dominant Iris colour percentage in a data frame.\n",
    "#     '''\n",
    "\n",
    "path='/home/roopesh/Desktop/New_Corpus/Brown/front (3).jpg'\n",
    "image = cv2.imread(path)\n",
    "\n",
    "#     plt.imshow(image)\n",
    "#     plt.show()\n",
    "\n",
    "# conversion numpy array into rgb image to show\n",
    "\n",
    "\n",
    "image_bgr_rgb = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # converting from BGR to RGB\n",
    "\n",
    "out = image_bgr_rgb.copy()\n",
    "out_pupile = image_bgr_rgb.copy()\n",
    "\n",
    "result = iris_detector.detect(image_bgr_rgb)\n",
    "\n",
    "if not result is None:\n",
    "\n",
    "    detected_pupils = result.detected_pupils,\n",
    "    face_rect_detection = result.face_rect_detection_from_landmarks,\n",
    "    face_rect_landmarks = result.face_rect_from_landmarks,\n",
    "    face_landmarks = result.face_landmarks,\n",
    "    face_rect_detection_from = result.face_rect_from_detection,\n",
    "    face_landmarks_from_detection = result.face_landmarks_from_detection,\n",
    "    left_iris_landmarks = result.left_iris_landmarks,\n",
    "    left_eyelid_landmarks = result.left_eyelid_landmarks,\n",
    "    right_iris_landmarks = result.right_iris_landmarks,\n",
    "    right_eyelid_landmarks = result.right_eyelid_landmarks,\n",
    "    left_iris_segmentation = result.left_iris_segmentation,\n",
    "    right_iris_segmentation = result.right_iris_segmentation,\n",
    "    eyes_landmarks = result.eyes_landmarks\n",
    "\n",
    "    #         out_pupile_ = draw.draw_pupils(out_pupile, result.detected_pupils.left, result.detected_pupils.right, color_center = (255, 255, 255), color_contour = (255, 255, 255))\n",
    "    #         out_pupile_ = draw.draw_rect(out_pupile_, result.face_rect_detection_from_landmarks, thickness=2, color=(255, 0, 0))\n",
    "    #         out_pupile_ = draw.draw_list_pointd(out_pupile_, result.left_iris_landmarks,radius=3,color = (255, 255, 255))\n",
    "\n",
    "    out_= draw.draw_contour(out, result.left_iris_segmentation,  thickness=4,color=(0, 0, 0))\n",
    "\n",
    "    \n",
    "    # flattening tuple of tuples of left iris landmarks into a list\n",
    "\n",
    "    left_iris_tuple_of_tuple_Tolist = ([PointD_elements for PointD in left_iris_landmarks for PointD_elements in PointD])\n",
    "\n",
    "    # Extraction of Points From LEFT IRIS Landmarks: Left Iris from Coder's Point of view\n",
    "\n",
    "    left_iris_points = [(pointD.x, pointD.y) for pointD in left_iris_tuple_of_tuple_Tolist]\n",
    "\n",
    "    center_point_LeftIris=(np.round(left_iris_points[0]))\n",
    "    for left_x,left_y in [center_point_LeftIris]:\n",
    "         lx, ly = left_x, left_y\n",
    "\n",
    "    left_point_LeftIris=(np.round(left_iris_points[1]))\n",
    "    for leftIris_left_x,LeftIris_left_y in [left_point_LeftIris]:\n",
    "        LIL_x, LIL_y = leftIris_left_x, LeftIris_left_y\n",
    "\n",
    "    right_point_LeftIris=(np.round(left_iris_points[3]))\n",
    "    for rightIris_x,rightIris_y in [right_point_LeftIris]:\n",
    "        RIL_x, RIL_y = rightIris_x, rightIris_y\n",
    "\n",
    "    Top_point_LeftIris=(np.round(left_iris_points[2]))\n",
    "    for TopIris_x,TopIris_y in [Top_point_LeftIris]:\n",
    "        TI_x, TI_y = TopIris_x, TopIris_y\n",
    "\n",
    "    Bottom_point_LeftIris=(np.round(left_iris_points[4]))\n",
    "    for BottomIris_x,BottomIris_y in [Bottom_point_LeftIris]:\n",
    "        BI_x, BI_y = BottomIris_x, BottomIris_y\n",
    "\n",
    "\n",
    "    #    Extract Eye Lids \n",
    "    eldt_lid_tuple_to_list=[pointe_elements for point in left_eyelid_landmarks for pointe_elements in point]\n",
    "    lef_eye_lid=[(pointe.x,pointe.y) for pointe in eldt_lid_tuple_to_list]\n",
    "    #             print(lef_eye_lid)\n",
    "\n",
    "    point_0= (np.round(lef_eye_lid[0]))\n",
    "    for p0x,p0y in [point_0]:\n",
    "        pointx0,pointy0= p0x,p0y\n",
    "\n",
    "    point_1= (np.round(lef_eye_lid[1]))\n",
    "    for p1x,p1y in [point_1]:\n",
    "        pointx1,pointy1= p1x,p1y \n",
    "\n",
    "    point_2= (np.round(lef_eye_lid[2]))\n",
    "    for p2x,p2y in [point_2]:\n",
    "        pointx2,pointy2= p2x,p2y\n",
    "\n",
    "    point_3= (np.round(lef_eye_lid[3]))\n",
    "    for p3x,p3y in [point_3]:\n",
    "        pointx3,pointy3=  p3x,p3y \n",
    "\n",
    "    point_4= (np.round(lef_eye_lid[4]))\n",
    "    for p4x,p4y in [point_4]:\n",
    "        pointx4,pointy4= p4x,p4y\n",
    "\n",
    "    point_5= (np.round(lef_eye_lid[5]))\n",
    "    for p5x,p5y in [point_5]:\n",
    "        pointx5,pointy5= p5x,p5y\n",
    "\n",
    "    point_6= (np.round(lef_eye_lid[6]))\n",
    "    for p6x,p6y in [point_6]:\n",
    "        pointx6,pointy6= p6x,p6y\n",
    "\n",
    "    point_7= (np.round(lef_eye_lid[7]))\n",
    "    for p7x,p7y in [point_7]:\n",
    "        pointx7,pointy7= p7x,p7y\n",
    "\n",
    "    point_8= (np.round(lef_eye_lid[8]))\n",
    "    for p8x,p8y in [point_8]:\n",
    "        pointx8,pointy8= p8x,p8y\n",
    "\n",
    "    point_9= (np.round(lef_eye_lid[9]))\n",
    "    for p9x,p9y in [point_9]:\n",
    "        pointx9,pointy9= p9x,p9y\n",
    "\n",
    "    point_10= (np.round(lef_eye_lid[10]))\n",
    "    for p10x,p10y in [point_10]:\n",
    "        pointx10,pointy10= p10x,p10y\n",
    "\n",
    "    point_11= (np.round(lef_eye_lid[11]))\n",
    "    for p11x,p11y in [point_11]:\n",
    "        pointx11,pointy11= p11x,p11y\n",
    "\n",
    "    point_12= (np.round(lef_eye_lid[12]))\n",
    "    for p12x,p12y in [point_12]:\n",
    "        pointx12,pointy12= p12x,p12y\n",
    "\n",
    "    point_13= (np.round(lef_eye_lid[13]))\n",
    "    for p13x,p13y in [point_13]:\n",
    "        pointx13,pointy13= p13x,p13y\n",
    "\n",
    "    point_14= (np.round(lef_eye_lid[14]))\n",
    "    for p14x,p14y in [point_14]:\n",
    "        pointx14,pointy14= p14x,p14y\n",
    "\n",
    "\n",
    "    # Distance Formula to calculate the distance between center to left_Iris_ points to get radius of iris\n",
    "    distance_left_iris_center = np.sqrt((lx - LIL_x) ** 2 + (ly - LIL_y) ** 2)\n",
    "    \n",
    "    # distance between point 4 and center of iris\n",
    "    distance_point_4_iris_center = np.sqrt((lx - p4x) ** 2 + (ly - p4y) ** 2)\n",
    "\n",
    "#  First Circular mask to take inner pupil area alone\n",
    "\n",
    "    mask = np.zeros(out_.shape, dtype=np.uint8)     # Result from Mediapipe added here for second mask.\n",
    "    center= (int(left_x),int(left_y))\n",
    "    radius = (int((distance_left_iris_center)*0.20))      \n",
    "    left_mask = cv2.circle(mask, center, radius, (255, 255, 255), -1 )\n",
    "    result = cv2.bitwise_and(out_, left_mask)  \n",
    "    result[mask==0] = 255                                 # adding background Color- white\n",
    "   \n",
    "\n",
    "    # Cropping the inner pupil area from the second circular masked image (size should be same as the first masked and cropped result )\n",
    "\n",
    "    x= int(pointx12)       # x-axis --Landmarks points from \n",
    "    y= int(pointy11)     # y-axis --Landmarks points from \n",
    "    h= int(distance_point_4_iris_center*1.5)   # height --\n",
    "    w=int(radius*2.35)   # width  --Radius of iris times 2.35 for adjustment\n",
    "    crop = result[y:y+h, x:x+w]\n",
    "    \n",
    "    \n",
    "# second Circular mask to take inner pupil area alone\n",
    "    \n",
    "    mask1 = np.zeros(out_.shape, dtype=np.uint8)     # Result from Mediapipe added here for second mask.\n",
    "    center1= (int(left_x),int(left_y))\n",
    "    radius1 = (int((radius)* 0.30))     # to scrap pupil area and other reflection area\n",
    "    left_mask1 = cv2.circle(mask1, center1, radius1, (255, 255, 255), -1 )\n",
    "    result1 = cv2.bitwise_and(out_, left_mask1-255)  # subtracting white region over masked area\n",
    "    result1[mask1==0] = 255                                 # adding background Color- white\n",
    "\n",
    "# Cropping the inner pupil area from the second circular masked image (size should be same as the first masked and cropped result )\n",
    "\n",
    "    x1= int(pointx12)        # x-axis --Landmarks points from top-\n",
    "    y1= int(pointy11)         # y-axis --Landmarks points from top_ \n",
    "    h1= int(distance_point_4_iris_center*1.5)   # height -\n",
    "    w1=int(radius*2.35)    # width  --Radius of iris times 2.35 for adjustment\n",
    "    crop1 = result1[y1:y1+h1, x1:x1+w1]\n",
    "    \n",
    "# Bitwise and operation to omit the inner pupil alone and take the rest of the iris area\n",
    "    \n",
    "    adding_both_cropped_image = cv2.bitwise_and(crop, crop1)\n",
    "    \n",
    "\n",
    "# Removing NOISE from the Adding_both_cropped_image (<=10,  >=240) in all channel\n",
    "\n",
    "    final_result = np.array(adding_both_cropped_image)\n",
    "    mask = np.all(final_result <= [10, 10, 10], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    mask = np.all(final_result >= [240, 240, 240], axis=2)\n",
    "    final_result[mask] = [0, 0, 0]\n",
    "    annular_result = final_result                   # the final result of the iris area from mediapipe\n",
    "\n",
    "    pil_image = Image.fromarray(annular_result)     # input from the annular_result read as array\n",
    "    imarray = np.array(pil_image.getdata())\n",
    "    df = pd.DataFrame(imarray, columns=['RED', 'GREEN', 'BLUE'])\n",
    "    df = pd.DataFrame(df[(df['RED'] >= 50) | (df['GREEN'] >= 50) | (df['BLUE'] >= 50)])  # For value greater than 50\n",
    "\n",
    "    # K-Means Clustering using Scipy\n",
    "\n",
    "    cluster_size = 3\n",
    "    cluster_centers, _ = kmeans(df.values.astype(float), cluster_size)\n",
    "    index, _ = vq(df.values.astype(float), cluster_centers)\n",
    "    count = np.bincount(index)\n",
    "    sum = np.sum(count)\n",
    "    i, Blue, Green, Brown,Other = 0, 0, 0, 0, 0\n",
    "    for row in cluster_centers:\n",
    "        r = row[0]\n",
    "        g = row[1]\n",
    "        b = row[2]\n",
    "        h, s, v = rgb_to_hsv(r, g, b)   # calling the function to convert RGB to HSV\n",
    "        percent = count[i]*100/sum\n",
    "        if h >= 170 and h < 270:\n",
    "            Blue += percent\n",
    "        elif h >= 60 and h < 170:\n",
    "            Green += percent\n",
    "        elif h >= 300 or h < 40:\n",
    "            Brown += percent\n",
    "        else:\n",
    "            Other += percent\n",
    "        i+=1\n",
    "\n",
    "# Results of Dominant Color Detection in dataframe\n",
    "\n",
    "    data = [[path, int(Blue), int(Green), int(Brown), int(Other)]]\n",
    "    dominantColour_ = pd.DataFrame(data, columns=['File_name :', 'Blue % :', 'Green % :', 'Brown % :','Other % :']).T\n",
    "    print(dominantColour_)\n",
    "#     return(dominantColour_)\n",
    "else: print(\"No face detected :\", file)\n",
    "\n",
    " # **************************  END of Dominant Colour Detection **************************\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(final_result)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RED</th>\n",
       "      <th>GREEN</th>\n",
       "      <th>BLUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>51</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>55</td>\n",
       "      <td>37</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>52</td>\n",
       "      <td>36</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>54</td>\n",
       "      <td>37</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19899</th>\n",
       "      <td>53</td>\n",
       "      <td>48</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19900</th>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>64</td>\n",
       "      <td>55</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19902</th>\n",
       "      <td>67</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>71</td>\n",
       "      <td>62</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RED  GREEN  BLUE\n",
       "128     51     35    20\n",
       "129     55     37    25\n",
       "130     52     36    21\n",
       "298     54     37    27\n",
       "299     51     37    24\n",
       "...    ...    ...   ...\n",
       "19899   53     48    42\n",
       "19900   61     53    42\n",
       "19901   64     55    40\n",
       "19902   67     58    43\n",
       "19903   71     62    47\n",
       "\n",
       "[1926 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  First Circular mask to take inner pupil area alone\n",
    "\n",
    "mask = np.zeros(out_.shape, dtype=np.uint8)     # Result from Mediapipe added here for second mask.\n",
    "center= (int(left_x),int(left_y))\n",
    "radius = (int((distance_left_iris_center)*0.20))      \n",
    "left_mask = cv2.circle(mask, center, radius, (255, 255, 255), -1 )\n",
    "result = cv2.bitwise_and(out_, left_mask)  \n",
    "result[mask==0] = 255                                 # adding background Color- white\n",
    "\n",
    "# Cropping the inner pupil area from the second circular masked image (size should be same as the first masked and cropped result )\n",
    "\n",
    "x= int(pointx12)       # x-axis --Landmarks points from \n",
    "y= int(pointy11)     # y-axis --Landmarks points from \n",
    "h= int(distance_point_4_iris_center*1.5)   # height --\n",
    "w=int(radius*2.35)   # width  --Radius of iris times 2.35 for adjustment\n",
    "crop = result[y:y+h, x:x+w]\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(crop)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newPython3.8",
   "language": "python",
   "name": "newpython3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
